#!/usr/bin/env python3
"""
Generated Clustering Model
==========================

Model Type: {{ model_type }}
Algorithm: {{ algorithm }}
Data Path: {{ data_path }}

This model groups similar data points together.
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.cluster import DBSCAN, AgglomerativeClustering, KMeans
from sklearn.metrics import calinski_harabasz_score, silhouette_score
from sklearn.preprocessing import StandardScaler


def load_and_preprocess_data(data_path: str):
    """Load and preprocess the data for clustering."""
    print(f"ğŸ“Š Loading data from: {data_path}")
    
    # Load data
    df = pd.read_csv(data_path)
    print(f"   Shape: {df.shape}")
    print(f"   Columns: {list(df.columns)}")
    
    # Remove non-numeric columns for clustering
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    df_numeric = df[numeric_columns]
    
    print(f"   Numeric columns: {list(numeric_columns)}")
    
    # Handle missing values
    df_numeric = df_numeric.fillna(df_numeric.mean())
    
    # Scale the features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df_numeric)
    
    return X_scaled, df_numeric, scaler

def create_clustering_model(algorithm: str, n_clusters: int = 3):
    """Create clustering model based on algorithm."""
    if algorithm == "kmeans":
        model = KMeans(n_clusters=n_clusters, random_state=42)
    elif algorithm == "dbscan":
        model = DBSCAN(eps=0.5, min_samples=5)
    elif algorithm == "hierarchical":
        model = AgglomerativeClustering(n_clusters=n_clusters)
    else:
        # Default to KMeans
        model = KMeans(n_clusters=n_clusters, random_state=42)
    
    return model

def evaluate_clustering(X, labels):
    """Evaluate clustering quality."""
    if len(set(labels)) > 1:  # Need at least 2 clusters for evaluation
        try:
            silhouette = silhouette_score(X, labels)
            calinski = calinski_harabasz_score(X, labels)
            
            print(f"ğŸ“ˆ Clustering Evaluation:")
            print(f"   Silhouette Score: {silhouette:.4f}")
            print(f"   Calinski-Harabasz Score: {calinski:.4f}")
            
            return {
                "silhouette_score": silhouette,
                "calinski_harabasz_score": calinski
            }
        except Exception as e:
            print(f"âš ï¸ Could not compute evaluation metrics: {e}")
            return {}
    else:
        print("âš ï¸ Only one cluster found - cannot evaluate")
        return {}

def visualize_clusters(X, labels, feature_names):
    """Visualize clustering results."""
    try:
        # If we have more than 2 features, use PCA for visualization
        if X.shape[1] > 2:
            from sklearn.decomposition import PCA
            pca = PCA(n_components=2)
            X_pca = pca.fit_transform(X)
            print(f"ğŸ“Š Using PCA for visualization (explained variance: {pca.explained_variance_ratio_.sum():.2f})")
        else:
            X_pca = X
        
        # Create visualization
        plt.figure(figsize=(10, 8))
        
        # Scatter plot
        scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', alpha=0.7)
        plt.colorbar(scatter)
        
        plt.title(f'Clustering Results - {{ algorithm }}')
        plt.xlabel('Feature 1')
        plt.ylabel('Feature 2')
        
        # Add cluster centers for KMeans
        if '{{ algorithm }}' == 'kmeans':
            from sklearn.decomposition import PCA
            pca = PCA(n_components=2)
            centers_pca = pca.fit_transform(model.cluster_centers_)
            plt.scatter(centers_pca[:, 0], centers_pca[:, 1], c='red', marker='x', s=200, linewidths=3, label='Centroids')
            plt.legend()
        
        plt.tight_layout()
        plt.savefig('/tmp/clustering_results.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š Visualization saved to: /tmp/clustering_results.png")
        
    except Exception as e:
        print(f"âš ï¸ Could not create visualization: {e}")

def main():
    """Main clustering pipeline."""
    print("ğŸš€ Starting Clustering Analysis")
    print("=" * 50)
    
    # Load and preprocess data
    X_scaled, df_numeric, scaler = load_and_preprocess_data("{{ data_path }}")
    
    # Determine optimal number of clusters (for KMeans)
    if '{{ algorithm }}' == 'kmeans':
        print("\nğŸ” Finding optimal number of clusters...")
        silhouette_scores = []
        K_range = range(2, min(11, len(X_scaled) // 10 + 1))
        
        for k in K_range:
            kmeans = KMeans(n_clusters=k, random_state=42)
            labels = kmeans.fit_predict(X_scaled)
            if len(set(labels)) > 1:
                score = silhouette_score(X_scaled, labels)
                silhouette_scores.append(score)
            else:
                silhouette_scores.append(0)
        
        optimal_k = K_range[np.argmax(silhouette_scores)]
        print(f"   Optimal number of clusters: {optimal_k}")
        n_clusters = optimal_k
    else:
        n_clusters = 3  # Default for other algorithms
    
    # Create and fit model
    print(f"\nğŸ¤– Training {{ algorithm }} model...")
    model = create_clustering_model("{{ algorithm }}", n_clusters)
    labels = model.fit_predict(X_scaled)
    
    # Print results
    unique_labels = set(labels)
    print(f"   Number of clusters found: {len(unique_labels)}")
    for label in sorted(unique_labels):
        count = (labels == label).sum()
        print(f"   Cluster {label}: {count} samples")
    
    # Evaluate clustering
    print(f"\nğŸ“Š Evaluating clustering quality...")
    evaluation_results = evaluate_clustering(X_scaled, labels)
    
    # Visualize results
    print(f"\nğŸ“ˆ Creating visualization...")
    visualize_clusters(X_scaled, labels, list(df_numeric.columns))
    
    # Save results
    results_df = df_numeric.copy()
    results_df['cluster'] = labels
    results_path = '/tmp/clustering_results.csv'
    results_df.to_csv(results_path, index=False)
    print(f"\nğŸ’¾ Results saved to: {results_path}")
    
    print("\nâœ… Clustering analysis completed!")
    print(f"ğŸ“ Files generated:")
    print(f"   - Clustering results: {results_path}")
    print(f"   - Visualization: /tmp/clustering_results.png")
    
    return model, labels, evaluation_results

if __name__ == "__main__":
    model, labels, evaluation_results = main() 